{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42aa9ae",
   "metadata": {},
   "source": [
    "# PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea897fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import export_graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "618906d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find RMSE MSE MAE R2\n",
    "\n",
    "def reg_metrics(y_test, y_pred, x_train,y_pred_train,y_train):\n",
    "    \n",
    "    #imports\n",
    "    from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "\n",
    "\n",
    "    #calculate\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "    MSE = mean_squared_error(y_test,y_pred)\n",
    "    MAE = mean_absolute_error(y_test,y_pred)\n",
    "    R2_Test = r2_score(y_test,y_pred)\n",
    "    R2_Train = r2_score(y_train,y_pred_train)\n",
    "    \n",
    "    #print\n",
    "    print(\"RMSE: \" + str(round(RMSE,3)))\n",
    "    print(\"MSE:  \" + str(round(MSE,3)))\n",
    "    print(\"MAE:  \" +  str(round(MAE,3)))\n",
    "    print(\"R2_Test:   \" + str(round(R2_Test,3)))\n",
    "    print(\"R2_Train:   \" + str(round(R2_Train,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b480e6cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Location_Brooklyn Heights'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17352\\2427881362.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#features + target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbookingHotels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Rate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Review'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TypeBed'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Prepayment'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Distance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'LengthOfStay'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TimeToTravel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Location_Union Square'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Location_Brooklyn Heights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbookingHotels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbookingHotels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Price'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Rate'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Review'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TypeBed'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Prepayment'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Distance'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'LengthOfStay'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TimeToTravel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Location_Union Square'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Location_Brooklyn Heights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3511\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5796\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5859\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5861\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Location_Brooklyn Heights'] not in index\""
     ]
    }
   ],
   "source": [
    "#Prepare the data\n",
    "\n",
    "bookingHotels = pd.read_csv('bookingHotelsClean.csv')\n",
    "\n",
    "\n",
    "#features + target\n",
    "\n",
    "x = bookingHotels[['Rate','Review','TypeBed','Prepayment','Distance','LengthOfStay','TimeToTravel','Location_Union Square','Location_Brooklyn Heights']]\n",
    "y = bookingHotels['Price']\n",
    "data = bookingHotels[['Price','Rate','Review','TypeBed','Prepayment','Distance','LengthOfStay','TimeToTravel','Location_Union Square','Location_Brooklyn Heights']]\n",
    "\n",
    "#test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a19fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "# Create model\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Actual vs Predict\n",
    "plt.title('Predict vs Actual')\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predict Price\")\n",
    "X = np.linspace(0,8000,100)\n",
    "Y = 1*X+0\n",
    "plt.plot(X, Y, '-r')\n",
    "plt.scatter(y_pred_test,y_test,alpha=0.25)\n",
    "plt.xticks(np.arange(0,10000,step=1000))\n",
    "plt.yticks(np.arange(0,10000,step=1000))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get importance\n",
    "plt.title('importance')\n",
    "importance = reg.coef_\n",
    "# summarize feature importance\n",
    "pyplot.bar([x.columns[j] for j in range(len(importance))], importance)\n",
    "pyplot.xticks(fontsize = 9,rotation=45)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Residual plot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#add constant to predictor variables\n",
    "x_r = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x_r).fit() \n",
    "\n",
    "\n",
    "#create instance of influence\n",
    "influence = model.get_influence()\n",
    "\n",
    "#obtain standardized residuals\n",
    "standardized_residuals = influence.resid_studentized_internal\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(bookingHotels['Price'], standardized_residuals,alpha=0.35)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Standardized Residuals')\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54c62a",
   "metadata": {},
   "source": [
    "In the expensive prices, the model is wrong in the upward direction, the model thinks that the prices are more expensive than they really are, our hypothesis is that the price behavior does not increase regularly.\n",
    "There is a certain stage where the price increases at a slower rate, so a linear model is not the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeRegressor\n",
    "\n",
    "# Create model\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "for i in range(1, 10):\n",
    "    print(\"\\n\",i, \")\")\n",
    "    for j in range(1,10):\n",
    "        print(\"\\n\",j, \")\")\n",
    "        \n",
    "       #check criterions \n",
    "        reg = tree.DecisionTreeRegressor(criterion='mse', max_depth=i , min_samples_leaf=j, random_state=101)\n",
    "        #reg = tree.DecisionTreeRegressor(criterion='friedman_mse', max_depth=i , min_samples_leaf=j, random_state=101)\n",
    "        #reg = tree.DecisionTreeRegressor(criterion='mae', max_depth=i , min_samples_leaf=j, random_state=101)\n",
    "        #reg = tree.DecisionTreeRegressor(criterion='poisson', max_depth=i , min_samples_leaf=j, random_state=101)\n",
    "\n",
    "# Train the model\n",
    "        \n",
    "        reg.fit(x_train, y_train)\n",
    "    \n",
    "# Make predictions\n",
    "        y_pred_test = reg.predict(x_test)\n",
    "        y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "        reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3128109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeRegressor\n",
    "\n",
    "# the best Tree regressor\n",
    " \n",
    "reg = tree.DecisionTreeRegressor(criterion='mse', max_depth=8 , min_samples_leaf=9, random_state=101)\n",
    "\n",
    "# Train the model\n",
    "        \n",
    "reg.fit(x_train, y_train)\n",
    "    \n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "#Visualisation\n",
    "# Plot the decision tree\n",
    "fig, ax = plt.subplots(figsize=(60, 50))\n",
    "tree.plot_tree(reg, filled=True, fontsize=12, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Residual plot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#add constant to predictor variables\n",
    "x_r = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x_r).fit() \n",
    "\n",
    "\n",
    "#create instance of influence\n",
    "influence = model.get_influence()\n",
    "\n",
    "#obtain standardized residuals\n",
    "standardized_residuals = influence.resid_studentized_internal\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(bookingHotels['Price'], standardized_residuals,alpha=0.35)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Standardized Residuals')\n",
    "plt.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GaussianProcessRegressor\n",
    "\n",
    "#Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(data)\n",
    "normalized = pd.DataFrame(scaled, columns = data.columns)\n",
    "sampled = normalized.sample(frac=0.25)\n",
    "x = sampled[['Rate','Review','TypeBed','Prepayment','Distance','LengthOfStay','TimeToTravel','L_Union Square','L_Brooklyn Heights']]\n",
    "y = sampled['Price']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)\n",
    "\n",
    "\n",
    "\n",
    "# Create model\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel , ExpSineSquared , RationalQuadratic, DotProduct\n",
    "kernel = DotProduct() + WhiteKernel(noise_level=0.5)\n",
    "reg = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b9eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GaussianProcessRegressor\n",
    "\n",
    "\n",
    "# Create model\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel , ExpSineSquared , RationalQuadratic\n",
    "kernel = 1.0 * ExpSineSquared(1.0, 5.0, periodicity_bounds=(1e-2, 1e1)) + WhiteKernel(\n",
    "    1e-1)\n",
    "reg = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749fab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GaussianProcessRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Create model\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\n",
    "kernel = ConstantKernel(1.0) + ConstantKernel(1.0) * RBF(10)  + WhiteKernel(5)\n",
    "reg = GaussianProcessRegressor(kernel=kernel)\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Regression\n",
    "\n",
    "#features + target\n",
    "\n",
    "x = bookingHotels[['Rate','Review','TypeBed','Prepayment','Distance','LengthOfStay','TimeToTravel','L_Union Square','L_Brooklyn Heights']]\n",
    "y = bookingHotels['Price']\n",
    "data = bookingHotels[['Price','Rate','Review','TypeBed','Prepayment','Distance','LengthOfStay','TimeToTravel','L_Union Square','L_Brooklyn Heights']]\n",
    "\n",
    "#test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)\n",
    "\n",
    "\n",
    "# Create model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "reg = GradientBoostingRegressor(random_state=101)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get importance\n",
    "plt.title('importance')\n",
    "importance = reg.feature_importances_\n",
    "# summarize feature importance\n",
    "pyplot.bar([x.columns[j] for j in range(len(importance))], importance)\n",
    "pyplot.xticks(fontsize = 9,rotation=45)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Residual plot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#add constant to predictor variables\n",
    "x_r = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x_r).fit() \n",
    "\n",
    "\n",
    "#create instance of influence\n",
    "influence = model.get_influence()\n",
    "\n",
    "#obtain standardized residuals\n",
    "standardized_residuals = influence.resid_studentized_internal\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8c270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLPRegressor\n",
    "\n",
    "# Create model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor(random_state=101)\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Residual plot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#add constant to predictor variables\n",
    "x_r = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x_r).fit() \n",
    "\n",
    "\n",
    "#create instance of influence\n",
    "influence = model.get_influence()\n",
    "\n",
    "#obtain standardized residuals\n",
    "standardized_residuals = influence.resid_studentized_internal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d7ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elastic Net Regression\n",
    "\n",
    "\n",
    "#Create model\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "reg = ElasticNet(random_state=101)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "# get importance\n",
    "plt.title('importance')\n",
    "importance = reg.coef_\n",
    "# summarize feature importance\n",
    "pyplot.bar([x.columns[j] for j in range(len(importance))], importance)\n",
    "pyplot.xticks(fontsize = 9,rotation=45)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Residual plot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#add constant to predictor variables\n",
    "x_r = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x_r).fit() \n",
    "\n",
    "\n",
    "#create instance of influence\n",
    "influence = model.get_influence()\n",
    "\n",
    "#obtain standardized residuals\n",
    "standardized_residuals = influence.resid_studentized_internal\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#More Features\n",
    "\n",
    "#Day_of_week_snapshot\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "Day_of_week_snapshot = []\n",
    "for fulldate in bookingHotels[\"SnapShotDate\"]:\n",
    "\tdate_format = '%Y-%m-%d'\n",
    "\tdate = datetime.strptime(fulldate, date_format)\n",
    "\tDay_of_week_snapshot.append(date.strftime('%w'))\n",
    "bookingHotels[\"Day_of_week_snapshot\"] = Day_of_week_snapshot\n",
    "bookingHotels = bookingHotels.astype({\"Day_of_week_snapshot\":int})\n",
    "bookingHotels[\"Day_of_week_snapshot\"] += 1\n",
    "\n",
    "\n",
    "#Number of weekend days\n",
    "import datetime\n",
    "from datetime import datetime , timedelta\n",
    "\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "                \n",
    "Number_of_weekend_days = []\n",
    "for start,end in zip(bookingHotels.Start_Date,bookingHotels.End_Date):\n",
    "    count=0\n",
    "    date_format = '%Y-%m-%d'\n",
    "    start = datetime.strptime(start, date_format)\n",
    "    end = datetime.strptime(end, date_format)\n",
    "    for single_date in daterange(start, end):\n",
    "        day_of_week = int(single_date.strftime('%w'))+1\n",
    "        if day_of_week in [5,6,7]:\n",
    "            count=count+1        \n",
    "    Number_of_weekend_days.append(count)\n",
    "bookingHotels[\"Number_of_weekend_days\"] = Number_of_weekend_days\n",
    "bookingHotels = bookingHotels.astype({\"Number_of_weekend_days\":\"int\"})\n",
    "\n",
    "\n",
    "#price for night\n",
    "\n",
    "bookingHotels['Price_per_night'] = bookingHotels['Price']/ bookingHotels['LengthOfStay']\n",
    "\n",
    "#Day of month check in\n",
    "\n",
    "Day_of_month_check_in = []\n",
    "for date in bookingHotels[\"Start_Date\"]:\n",
    "\tdate_format = '%Y-%m-%d'\n",
    "\tdate = datetime.strptime(date, date_format)\n",
    "\tDay_of_month_check_in.append(date.strftime('%d'))\n",
    "bookingHotels[\"Day_of_month_check_in\"] = Day_of_month_check_in\n",
    "bookingHotels = bookingHotels.astype({\"Day_of_month_check_in\":int})\n",
    "\n",
    "\n",
    "#Day of month check out\n",
    "\n",
    "Day_of_month_check_out = []\n",
    "for date in bookingHotels[\"End_Date\"]:\n",
    "\tdate_format = '%Y-%m-%d'\n",
    "\tdate = datetime.strptime(date, date_format)\n",
    "\tDay_of_month_check_out.append(date.strftime('%d'))\n",
    "bookingHotels[\"Day_of_month_check_out\"] = Day_of_month_check_out\n",
    "bookingHotels = bookingHotels.astype({\"Day_of_month_check_out\":int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction with new features\n",
    "\n",
    "#features + target\n",
    "\n",
    "x = bookingHotels[['Day_of_week_snapshot','Number_of_weekend_days','Day_of_month_check_in','Day_of_month_check_out','Rate','Review','TypeBed','Prepayment','Distance','LengthOfStay','TimeToTravel','L_Union Square','L_Brooklyn Heights']]\n",
    "y = bookingHotels['Price']\n",
    "data = bookingHotels[['Rate','Review','LengthOfStay','Price','Day_of_week_snapshot','Number_of_weekend_days','Day_of_month_check_in','Day_of_month_check_out']]\n",
    "\n",
    "\n",
    "#test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)\n",
    "\n",
    "\n",
    "\n",
    "#LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "# Create model\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "#visualisation\n",
    "plt.title('Predict vs Actual')\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predict Price\")\n",
    "plt.scatter(y_test, y_pred_test,alpha=0.25)\n",
    "plt.xticks(np.arange(0,7000,step=1000))\n",
    "plt.yticks(np.arange(0,7000,step=500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff536d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Regression\n",
    "\n",
    "\n",
    "# Create model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "reg = GradientBoostingRegressor(random_state=101)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get importance\n",
    "plt.title('importance')\n",
    "importance = reg.feature_importances_\n",
    "# summarize feature importance\n",
    "pyplot.bar([x.columns[j] for j in range(len(importance))], importance)\n",
    "pyplot.xticks(fontsize = 9,rotation=45)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Residual plot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#add constant to predictor variables\n",
    "x_r = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x_r).fit() \n",
    "\n",
    "\n",
    "#create instance of influence\n",
    "influence = model.get_influence()\n",
    "\n",
    "#obtain standardized residuals\n",
    "standardized_residuals = influence.resid_studentized_internal\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04357769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newsplit\n",
    "\n",
    "\n",
    "#Gradient Boosting Regression\n",
    "\n",
    "\n",
    "train = bookingHotels[bookingHotels.TimeToTravel < 25]\n",
    "test = bookingHotels[bookingHotels.TimeToTravel > 25]\n",
    "x_train = train[['Rate','Review','TypeBed','Prepayment','Distance','LengthOfStay','TimeToTravel','L_Union Square','L_Brooklyn Heights']]\n",
    "x_test =  test[['Rate','Review','TypeBed','Prepayment','Distance','LengthOfStay','TimeToTravel','L_Union Square','L_Brooklyn Heights']]\n",
    "y_train = train['Price']\n",
    "y_test =  test['Price']\n",
    "\n",
    "\n",
    "\n",
    "# Create model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "reg = GradientBoostingRegressor(random_state=101)\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = reg.predict(x_test)\n",
    "y_pred_train = reg.predict(x_train)\n",
    "\n",
    "\n",
    "#Calculate\n",
    "reg_metrics(y_test, y_pred_test, x_train,y_pred_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Residual plot\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#add constant to predictor variables\n",
    "x_r = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x_r).fit() \n",
    "\n",
    "\n",
    "#create instance of influence\n",
    "influence = model.get_influence()\n",
    "\n",
    "#obtain standardized residuals\n",
    "standardized_residuals = influence.resid_studentized_internal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the csv file\n",
    "bookingHotels.to_csv('bookingHotelsClean2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945dad1",
   "metadata": {},
   "source": [
    "conclusions:\n",
    "\n",
    "1. The gradient boost gave the best results.<br />\n",
    "2. After we added the features our models gave better result.<br />\n",
    "3. After a different distribution of the train and the test, you can see that the models still give good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a920582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
